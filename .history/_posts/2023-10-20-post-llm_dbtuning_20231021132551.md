---
title: "From DB-BERT to DB-BART and Beyond"
last_modified_at: 2023-10-20T16:20:02-05:00
categories:
  - Knob
tags:
  - Database Knob Tuning
  - Pre-trained Language Model
  - DB-BERT
classes: wide
---

## Brief Introduction to Database Knob Tuning
Modern database management systems (DBMS) expose hundreds of configurable parameters (i.e., knobs) to control system behaviors.
Selecting appropriate values for these knobs is crucial to improve DBMS performance (e.g., set knob 'shared_buffers' from PostgreSQL to 25% of the RAM to improve performance).

![DBMS-Knob-Tuning](/assets/images/knob_tuning.png){: width="40%"}

As a common practice, experienced Database Administrators (DBAs) take great efforts (e.g., weeks or even months) to tune the target DBMS for a given workload (i.e., a workload is a set of SQL statements).

![DBA-Tuning](/assets/images/human_tuning.png){: width="40%"}

However, manual tuning struggles to handle different workloads, hardware environments, especially in nowadays cloud environments. Thus Machine Learning (ML)-based tuning systems are proposed to search for well-performing knob configurations automatically. They can be classified into two main categories: Bayesian Optimization (BO)-based and Reinforcement Learning (RL)-based. The algorithm details are omitted here, please refer to [OtterTune](https://db.cs.cmu.edu/projects/ottertune/) and [CDBTune](https://dl.acm.org/doi/10.1145/3299869.3300085) for more details, which are the representative works for BO-based and RL-based methods, respectively. 

## DB-BERT
While traditional ML-based DBMS tuning methods do possess the potential to eventually reach well-performing knob configurations, they often come at the cost of being resource-intensive and requiring a considerable number of iterations to achieve convergence. Such high costs come from the complexity of the 


## DB-BART

## First Try on DB-GPT-4

## Limitation of DB-BERT Series

## Beyond DB-BERT Series: GPTuner

## Comparison between DB-BERT Series and GPTuner