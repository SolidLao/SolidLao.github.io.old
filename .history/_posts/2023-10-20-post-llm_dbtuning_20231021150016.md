---
title: "From DB-BERT to DB-BART and Beyond"
last_modified_at: 2023-10-20T16:20:02-05:00
categories:
  - Knob
tags:
  - Database Knob Tuning
  - Pre-trained Language Model
  - DB-BERT
classes: wide
---

## Brief Introduction to Database Knob Tuning
Modern database management systems (DBMS) expose hundreds of configurable parameters (i.e., knobs) to control system behaviors.
Selecting appropriate values for these knobs is crucial to improve DBMS performance (e.g., set knob 'shared_buffers' from PostgreSQL to 25% of the RAM to improve performance).

![DBMS-Knob-Tuning](/assets/images/knob_tuning.png){: width="40%"}

As a common practice, experienced Database Administrators (DBAs) take great efforts (e.g., weeks or even months) to tune the target DBMS for a given workload (i.e., a workload is a set of SQL statements).

![DBA-Tuning](/assets/images/human_tuning.png){: width="40%"}

However, manual tuning struggles to handle different workloads, hardware environments, especially in nowadays cloud environments. Thus Machine Learning (ML)-based tuning systems are proposed to search for well-performing knob configurations automatically. They can be classified into two main categories: Bayesian Optimization (BO)-based and Reinforcement Learning (RL)-based. The algorithm details are omitted here, please refer to [OtterTune](https://db.cs.cmu.edu/projects/ottertune/) and [CDBTune](https://dl.acm.org/doi/10.1145/3299869.3300085) for more details, which are the representative works for BO-based and RL-based methods, respectively. 

## The Limitations of ML-based Tuning Systems
While ML-based DBMS tuning methods do possess the potential to eventually reach well-performing knob configurations, they often come at the cost of being resource-intensive and requiring a considerable number of iterations to achieve convergence (i.e., each iteration requires the stress-test for target workload on DBMS). Such high costs come from the complexity of the tuning problem: the configuration space is high-dimensional (e.g., PostgreSQL v14.7 has 351 knobs) and heterogeneous (e.g., a knob can be continual or categorical), and optimization algorithms struggle with this complexity. Instead of searching the configuration space only based on runtime feedback (i.e., black-box optimization), we can enhance the tuning process with domain knowledge because DBMS itself is domain-specific and there is extensive domain knowledge available from DBMS official documents, manuals, web forums. However, since such domain knowledge is expressed in natural language and seems exclusive to DBAs, the natural question is **how to make the knowledge understandable to machines and use the gained information to enhance the knob tuning process?**

## DB-BERT: a Database Tuning Tool that "Reads the Manual"
[DB-BERT](https://itrummer.github.io/dbbert/) is an excellent work that utilizes a pre-trained language model ([BERT](https://huggingface.co/docs/transformers/model_doc/bert)) to mine tuning hints from manuals and use the hints to guide the iterative optimization process (Specifically, the process is based on Double Deep Q-Networks, a Reinforcement Learning algorithm). 

### An Simple Example of Extracting Tuning Hints from Manuals
Given the following text snippet from [PostgreSQL official document](https://www.postgresql.org/docs/9.1/runtime-config-resource.html):

> a reasonable starting value for knob 'shared_buffers' is 25% of the memory in your system

The extracted tuning hint should be:

> shared_buffers = 0.25 * RAM

### How does DB-BERT work?
DB-BERT models the tuning process as three "Multiple Choice Question Answering" problems and utilize Reinforcement Learning to fine-tune a BERT model to answer the three problems. The three questions and the according choices are as follows:
- What is the relationship between the knob and the hardware?
  - answer 0: {param} and {value} relate to **main memory**
  - answer 1: {param} and {value} relate to **hard disk**
  - answer 2: {param} and {value} relate to **core counts**
  - answer 3: Set {param} to {value}
  - answer 4: {param} and {value} are **unrelated**

- How should I deviate the suggested value?
  - answer 0: Set {param} **much lower** than {value} 
  - answer 1: Set {param} **slightly below** {value}
  - answer 2: Set {param} **to** {value}
  - answer 3: Set {param} **slightly above** {value}
  - answer 4: Set {param} **much higher** than {value}

- How should I give weight for hints from different sources?
  - answer 0: The hint on {param} is **not important**
  - answer 1: The hint on {param} is **slightly important**
  - answer 2: The hint on {param} is **quite important**
  - answer 3: The hint on {param} is **very important**
  - answer 4: The hint on {param} is **extremely important**

For the second and the third problem, the according factors are {} and {}, respectively.

Given:
- a text snippet "a reasonable starting value for knob 'shared_buffers' is 25% of the memory in your system"
- hardware properties "RAM = 16 GB, Disk = 1 TB, Core Counts = 32"

DB-BERT works in the following ways:
- we at first extract the knob name and knob value from it: {shared_buffers, 0.25}.
- assume BERT answers the first question with answer '0', we get the expression: shared_buffers = 0.25 * 16 GB
- assume BERT answers the second question with answer '3', 

## From DB-BERT to DB-BART and DB-GPT-4


## Beyond DB-BERT Series: GPTuner


## Comparison between DB-BERT Series and GPTuner