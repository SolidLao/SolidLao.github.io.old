---
title: "GPTuner"
date: 2023-10-14
priority: 1
excerpt: "GPTuner is a database tuning system that leverages Large Language Model to handle domain knowledge and then enhance knob tuning procedure"
layout: single
author_profile: true
classes: wide
advisors:
  - name: "Prof. Jianguo Wang from Purdue University"
    url: "https://www.cs.purdue.edu/homes/csjgwang/"
  - name: "Prof. Mingjie Tang from Sichuan University"
    url: "http://merlintang.github.io/"
outcome:
  paper_title: "GPTuner: A Manual-Reading Database Tuning System via GPT-Guided Bayesian Optimization"
  authors: 
    - "Jiale Lao"
    - "Yibo Wang"
    - "Yufei Li"
    - "Zhiyuan Chen"
    - "Yunjia Zhang"
    - "Mingjie Tang"
    - "Jianguo Wang"
  paper_state: "In submission to VLDB 2024"
---

## Advisor

- [Prof. Jianguo Wang](https://www.cs.purdue.edu/homes/csjgwang/) from [Purdue University](https://www.purdue.edu/)
- [Prof. Mingjie Tang](http://merlintang.github.io/) from [Sichuan University](https://www.scu.edu.cn/)

## Publication

GPTuner: A Manual-Reading Database Tuning System via GPT-Guided Bayesian Optimization [\[code\]](https://github.com/SolidLao/GPTuner)
- **Jiale Lao**, Yibo Wang, Yufei Li, Zhiyuan Chen, Yunjia Zhang, Mingjie Tang, Jianguo Wang
- In submission to VLDB 2024

## Abstract
Modern database management systems (DBMS) expose hundreds of configurable knobs to control system behaviours. Determining the appropriate values for these knobs to improve DBMS performance is a long-standing problem in the database community. As there is an increasing number of knobs to tune and each knob could be in continuous or categorical values, manual tuning becomes impractical. Recently, automatic tuning systems using machine learning methods have shown great potentials. However, existing approaches still incur significant tuning costs or only yields sub-optimal performance. This is because they either ignore the extensive domain knowledge available (e.g., DBMS manuals and forum discussions) and only rely on the runtime feedback of benchmark evaluations to guide the optimization, or they utilize the domain knowledge in a limited way. Hence, we propose GPTuner, a manual-reading database tuning system that leverages domain knowledge extensively and automatically to optimize search space and enhance the runtime feedback-based optimization process. Firstly, we develop a Large Language Model (LLM)-based pipeline to collect and refine heterogeneous knowledge, and propose a prompt ensemble algorithm to unify a structured view of the refined knowledge. Secondly, using the structured knowledge, we (1) design a workload-aware and training-free knob selection strategy, (2) develop a search space optimization technique considering the value range of each knob, and (3) propose a Coarse-to-Fine Bayesian Optimization Framework to explore the optimized space. Finally, we evaluate GPTuner under different benchmarks (TPC-C and TPC-H), metrics (throughput and latency) as well as DBMS (PostgreSQL and MySQL). Compared to the state-of-the-art approaches, GPTuner identifies better configurations in **16x** less time on average. Moreover, GPTuner achieves up to \textbf{30\%} performance improvement (higher throughput or lower latency) over the \textbf{best-performing} alternative.


## System Overview
![GPTuner](/assets/images/gptuner.png)

GPTuner is a manual-reading database tuning system to suggest a satisfactory knob configuration with reduced tuning costs. Above figure presents the tuning workflow and it involves six procedures. ① User provides the DBMS to be tuned (e.g., PostgreSQL or MySQL), the target workload, and the optimization objective (e.g., latency or throughput). ② GPTuner extracts tuning knowledge from LLM, cleans toxic knowledge and summarize the knowledge from all resources (e.g., GPT-4, DBMS manuals and Web contents). ③ GPTuner transfers the summarized knowledge into a structured format accessible to machines (e.g., JSON). ④ GPTuner prunes the search space in terms of data dimensionality by selecting important knobs to tune. ⑤ GPTuner utilizes the structured knowledge to optimize the space.  ⑥ GPTuner explores the optimized space using a Coarse-to-Fine Bayesian Optimization framework and finally ⑦  identifies a satisfactory knob configuration within resource limits. 

